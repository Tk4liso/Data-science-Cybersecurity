{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036bb05c-33d7-4ae2-ad54-099ccd8c82c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2565 - sparse_categorical_accuracy: 0.9269\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9654\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0784 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9827\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9876\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9914\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -5.913885 ,  -8.508826 ,  11.58493  , ..., -11.980821 ,\n",
       "         -2.5803628,  -5.1940904],\n",
       "       [ 18.75349  , -17.920616 ,  -9.192937 , ...,  -8.552802 ,\n",
       "         -7.071189 , -10.806072 ],\n",
       "       [-11.802656 , -10.261378 ,  -6.8189917, ...,  -1.1689671,\n",
       "         -3.1073961,   4.1730533],\n",
       "       ...,\n",
       "       [ -8.2736025,  -9.40512  ,   1.876831 , ..., -13.161524 ,\n",
       "         10.171167 ,  -3.6289816],\n",
       "       [ 14.021061 , -10.94169  ,   1.8975983, ..., -11.173404 ,\n",
       "        -12.240341 ,  -1.0961963],\n",
       "       [-12.517393 ,  -7.057191 , -10.277754 , ..., -14.159073 ,\n",
       "         -5.4150295,  -4.987723 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds \n",
    "\n",
    "# Carga del dataset pcap_mnist\n",
    "(pcap_data_train, pcap_data_test), pcap_ds_info = tfds.load( \n",
    "    'mnist', \n",
    "    split=['train', 'test'], \n",
    "    shuffle_files=True, \n",
    "    as_supervised=True, \n",
    "    with_info=True, \n",
    ") \n",
    "\n",
    "# Normalización de los datos\n",
    "def pcap_normalize_data(pcap_image, pcap_label): \n",
    "    # Convertir a float y asegurar forma (28, 28, 1)\n",
    "    pcap_image = tf.cast(pcap_image, tf.float32) / 255.\n",
    "    pcap_image = tf.reshape(pcap_image, [28, 28, 1])\n",
    "    return pcap_image, pcap_label\n",
    " \n",
    "\n",
    "# Normaliza el dataset de ENTRENAMIENTO\n",
    "pcap_data_train = pcap_data_train.map(\n",
    "    pcap_normalize_data, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "# Normaliza el dataset de PRUEBA\n",
    "pcap_data_test = pcap_data_test.map(\n",
    "    pcap_normalize_data,  \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ") \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "pcap_data_train = pcap_data_train.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "pcap_data_test = pcap_data_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Definición del modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compilación del modelo  \n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ") \n",
    "\n",
    "# Entrenamiento del modelo\n",
    "model.fit(pcap_data_train, epochs=6) \n",
    "\n",
    "# Predicción\n",
    "model.predict(pcap_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532dcb07-dc95-466e-9581-b5acfe460176",
   "metadata": {},
   "source": [
    "**Un ejemplo de análisis visual del tráfico de red**\n",
    "\n",
    " Preprocesamiento del conjunto de datos.\n",
    "\n",
    "Las líneas 2 a 3 abren los archivos de flujo de red divididos mediante el modo rb y el contenido leído se convierte a formato hexadecimal mediante la función binascii.hexlify(). El contenido hexadecimal actual se rellenará y recortará a 784 bits en las líneas 4 a 7. Las líneas 8 a 9 almacenan el contenido hexadecimal convertido para su posterior uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0aa4e-058f-47ad-979d-a1e3d6c3c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST_Preparing_session_png.py \n",
    "def getMatrixfrom_pcap(filename,width): \n",
    "with open (filename, 'rb') as f: \n",
    "      content = f.read() \n",
    "      hexst = binascii.hexlify(content) \n",
    "      fh = numpy.array([int (hexst[i: i+2],16) \n",
    "             for i in range (0, len(hexst), 2)]) \n",
    "      rn = len(fh)/width \n",
    "      fh = numpy.reshape(fh[:rn*width], (-1, width)) \n",
    "      fh = numpy. uint8(fh) \n",
    "      return fh "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c09ebc-f52c-429c-ab56-c9c01d3ee5eb",
   "metadata": {},
   "source": [
    "La línea 1 marca el inicio de una iteración, que se utiliza para gestionar todas las imágenes convertidas del flujo de red. Las líneas 2 y 3 definen matrices para almacenar la imagen y su etiqueta correspondiente. Las líneas 5 a 10 buscan los archivos que terminan en .png y los \n",
    "añaden a una lista. La línea 12 reorganiza los archivos en la lista y prepara el proceso de división del conjunto de datos. Este fragmento de código se encuentra en el siguiente enlace: \n",
    "https://github.com/PegX/Falcon/blob/master/4_Png2Mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516a5e4b-7f66-4541-a208-ee58403fee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Cargar el dataset MNIST\n",
    "(ds_train, _), _ = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)\n",
    "\n",
    "# Crear carpetas destino como 4_Png/Train/0, ..., 4_Png/Train/9\n",
    "base_dir = \"4_Png/Train\"\n",
    "for i in range(10):\n",
    "    os.makedirs(os.path.join(base_dir, str(i)), exist_ok=True)\n",
    "\n",
    "# Guardar imágenes como .png en sus carpetas respectivas\n",
    "count = 0\n",
    "for image, label in tfds.as_numpy(ds_train):\n",
    "    label_str = str(label)\n",
    "    img = Image.fromarray(image.squeeze(), mode='L')\n",
    "    img.save(os.path.join(base_dir, label_str, f\"{count}.png\"))\n",
    "    count += 1\n",
    "    if count >= 10:  # Limita a 10 imágenes\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de8ac42-fbf8-40b7-9e73-0e0d738ebad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from array import array\n",
    "from random import shuffle\n",
    "\n",
    "Names = [['4_Png\\Train','5_Mnist\\\\Train']]\n",
    "\n",
    "for name in Names:\n",
    "    data_image = array('B')\n",
    "    data_label = array('B')\n",
    "\n",
    "    FileList = []\n",
    "    for dirname in os.listdir(name[0]):\n",
    "        path = os.path.join(name[0], dirname)\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                FileList.append(os.path.join(name[0], dirname, filename))\n",
    "\n",
    "    shuffle(FileList)\n",
    "\n",
    "    for filename in FileList:\n",
    "        label = int(filename.split('\\\\')[2])\n",
    "        Im = Image.open(filename)\n",
    "        pixel = Im.load()\n",
    "        width, height = Im.size\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                data_image.append(pixel[y, x])\n",
    "        data_label.append(label)  # labels start (one unsigned byte each)\n",
    "\n",
    "    hexval = \"{0:#0{1}x}\".format(len(FileList), 6)  # number of files in HEX\n",
    "    hexval = '0x' + hexval[2:].zfill(8)\n",
    "\n",
    "    header = array('B')\n",
    "    header.extend([0, 0, 8, 1])\n",
    "    header.append(int('0x' + hexval[2:][0:2], 16))\n",
    "    header.append(int('0x' + hexval[2:][2:4], 16))\n",
    "    header.append(int('0x' + hexval[2:][4:6], 16))\n",
    "    header.append(int('0x' + hexval[2:][6:8], 16))\n",
    "\n",
    "    data_label = header + data_label\n",
    "\n",
    "    if max([width, height]) <= 256:\n",
    "        header.extend([0, 0, 0, width, 0, 0, 0, height])\n",
    "    else:\n",
    "        raise ValueError('Image exceeds maximum size: 256x256 pixels')\n",
    "\n",
    "    header[3] = 3  # Changing MSB for image data (0x00000803)\n",
    "    data_image = header + data_image\n",
    "\n",
    "    with open(name[1] + '-images-idx3-ubyte', 'wb') as output_file:\n",
    "        data_image.tofile(output_file)\n",
    "\n",
    "    with open(name[1] + '-labels-idx1-ubyte', 'wb') as output_file:\n",
    "        data_label.tofile(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19283209-4ed5-4f23-bb98-8622a4973ad6",
   "metadata": {},
   "source": [
    "Las líneas 14 a 22 presentan el proceso de lectura de la imagen y su etiqueta correspondiente en la memoria mediante la biblioteca Pillow. En nuestro caso, utilizamos las funciones Image.open() y load() en el atributo de tamaño de la imagen para almacenar las imágenes e incorporarlas al conjunto de datos.\n",
    "Las líneas 25 a 45 almacenan todas las imágenes y etiquetas leídas en cuatro archivos. Hay \n",
    "matrices de imágenes para entrenamiento y prueba, así como las etiquetas de entrenamiento \n",
    "y prueba. La segunda parte es el entrenamiento del modelo. Con el conjunto de datos de \n",
    "entrenamiento dividido y la red neuronal definida, entrenamos los modelos de IA con \n",
    "múltiples rondas. La última parte es la prueba o predicción del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7379ccf9-439c-4eac-af3d-636845bfc11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x292f209b400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.models.Sequential( \n",
    "[tf.keras.layers.Flatten(input_shape= (28,28)), \n",
    "tf.keras.layers.Dense(128, activation='relu'), \n",
    "tf.keras.layers.Dense(10)] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d22309-974f-497d-b59c-cd10ef96b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b3417d7-c2b4-4881-a61e-736f1644981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 5s 5ms/step - loss: 0.3550 - sparse_categorical_accuracy: 0.9018 - val_loss: 0.1857 - val_sparse_categorical_accuracy: 0.9470\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1598 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.1324 - val_sparse_categorical_accuracy: 0.9631\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1135 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9692\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9725\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.0834 - val_sparse_categorical_accuracy: 0.9743\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.0770 - val_sparse_categorical_accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x292f216d1f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compilar el modelo y declarar la función de pérdida y las métricas de rendimiento para el entrenamiento\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile( \n",
    "optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy( \n",
    "from_logits=True), \n",
    "metrics=[tf.keras.metrics.SparseCategoricalAccuracy()], \n",
    ") \n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12024100-89d6-48ca-ba0a-5e8937e53f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437123d4-f530-4210-83d0-3e6233786fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
